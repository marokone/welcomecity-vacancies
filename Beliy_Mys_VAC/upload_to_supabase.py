import math
import pandas as pd
import requests
from datetime import datetime, timezone

SUPABASE_URL = 'https://vhbiezamhpyejdqvvwuj.supabase.co'
SUPABASE_API_KEY = 'sb_publishable_PEUJVHuw56T2d3vA2iVMZA_POiY0MCX'
TABLE_NAME = 'vacancies_fw'

# –ü–æ–ª—è, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –≤—Ä—É—á–Ω—É—é –≤ –¢–∏–ª—å–¥–µ
MANUAL_FIELDS = ['description', 'requirements', 'responsibilities', 'conditions']

def _clean(v):
    """–û—á–∏—Å—Ç–∫–∞ –∑–Ω–∞—á–µ–Ω–∏–π: NaN/Inf/None/–ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ -> None"""
    if v is None:
        return None
    if isinstance(v, float):
        if math.isnan(v) or math.isinf(v):
            return None
    try:
        if pd.isna(v):
            return None
    except Exception:
        pass
    if isinstance(v, str):
        s = v.strip()
        if s == '' or s.lower() in ('nan', 'none', 'inf', '-inf'):
            return None
    return v

def is_field_empty(value):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø—É—Å—Ç–æ–µ –ª–∏ –ø–æ–ª–µ (None, NaN, –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞)"""
    cleaned = _clean(value)
    return cleaned is None or cleaned == ''

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV
csv_path = 'vacancies_rows.csv'
df_new = pd.read_csv(csv_path, dtype=str)
print(f'üì• –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –∏–∑ CSV: {len(df_new)}')

# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
df_new = df_new.astype(object).apply(lambda col: col.map(_clean))

headers = {
    'apikey': SUPABASE_API_KEY,
    'Authorization': f'Bearer {SUPABASE_API_KEY}',
    'Content-Type': 'application/json',
}

# –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∑–∞–ø–∏—Å–∏ –∏–∑ Supabase
print('üîç –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ Supabase...')
existing_resp = requests.get(
    f"{SUPABASE_URL}/rest/v1/{TABLE_NAME}?select=*",
    headers=headers,
)
existing_resp.raise_for_status()
existing_data = existing_resp.json()
print(f'üìä –ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –≤ Supabase: {len(existing_data)}')

# –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π –ø–æ job_id
existing_map = {str(item['job_id']): item for item in existing_data if item.get('job_id')}

# –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
records_to_upsert = []

for _, row in df_new.iterrows():
    record = row.to_dict()
    job_id = str(record.get('job_id'))
    
    # –ï—Å–ª–∏ –∑–∞–ø–∏—Å—å —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ Supabase
    if job_id in existing_map:
        existing = existing_map[job_id]
        
        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—è –ø—Ä–æ–≤–µ—Ä—è–µ–º: –µ—Å–ª–∏ –Ω–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø—É—Å—Ç–æ–µ, –æ—Å—Ç–∞–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ
        for field in MANUAL_FIELDS:
            if is_field_empty(record.get(field)):
                # –ï—Å–ª–∏ –≤ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª–µ –ø—É—Å—Ç–æ–µ, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ, —á—Ç–æ —É–∂–µ –µ—Å—Ç—å –≤ –ë–î
                record[field] = existing.get(field)
                print(f'  üîÑ –ü–æ–ª–µ {field} –¥–ª—è job_id {job_id}: –æ—Å—Ç–∞–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ')
            else:
                print(f'  ‚ú® –ü–æ–ª–µ {field} –¥–ª—è job_id {job_id}: –æ–±–Ω–æ–≤–ª—è–µ–º –∏–∑ —Ñ—Ä–µ–Ω–¥–≤–æ—Ä–∫–∞')
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞—Ç—ã
        now_iso = datetime.now(timezone.utc).isoformat()
        record['updated_at'] = now_iso
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –¥–∞—Ç—É —Å–æ–∑–¥–∞–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω–∞ –±—ã–ª–∞
        if not is_field_empty(record.get('created_at')):
            record['created_at'] = existing.get('created_at', record.get('created_at'))
    
    records_to_upsert.append(record)

print(f'\nüì¶ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è upsert: {len(records_to_upsert)}')

if not records_to_upsert:
    print('‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏')
    exit(0)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è upsert
upsert_headers = headers.copy()
upsert_headers['Prefer'] = 'resolution=merge-duplicates,return-minimal'

# –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
print('üöÄ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ Supabase...')
response = requests.post(
    f'{SUPABASE_URL}/rest/v1/{TABLE_NAME}',
    headers=upsert_headers,
    json=records_to_upsert
)

if response.ok:
    print(f'‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ/–æ–±–Ω–æ–≤–ª–µ–Ω–æ {len(records_to_upsert)} –∑–∞–ø–∏—Å–µ–π')
else:
    print(f'‚ùå –û—à–∏–±–∫–∞: {response.status_code}')
    print(response.text)
    
    # –ï—Å–ª–∏ –º–∞—Å—Å–æ–≤–∞—è –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∞, –ø—Ä–æ–±—É–µ–º –ø–æ –æ–¥–Ω–æ–π –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    print('\nüîß DEBUG: –ø—Ä–æ–±—É—é –ø–æ –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å–∏:')
    success_count = 0
    for i, record in enumerate(records_to_upsert, 1):
        print(f'  –ó–∞–ø–∏—Å—å {i}, job_id = {record.get("job_id")}')
        resp = requests.post(
            f'{SUPABASE_URL}/rest/v1/{TABLE_NAME}',
            headers=upsert_headers,
            json=[record]
        )
        if resp.ok:
            success_count += 1
            print(f'    ‚úÖ –£—Å–ø–µ—à–Ω–æ')
        else:
            print(f'    ‚ùå –û—à–∏–±–∫–∞: {resp.text}')
    
    print(f'\nüìä –ò—Ç–æ–≥: {success_count} –∏–∑ {len(records_to_upsert)} –∑–∞–ø–∏—Å–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ')
